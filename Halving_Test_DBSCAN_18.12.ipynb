{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517c4e9-568c-4f25-a345-1ad0e587b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm, matplotlib.colors\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import datasets, manifold\n",
    "\n",
    "from time import time\n",
    "import time\n",
    "import warnings\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "\n",
    "from sklearn.cluster import BisectingKMeans, KMeans\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data_1 = np.loadtxt('c12_data.txt', delimiter='\\t')\n",
    "data_2 = np.loadtxt('c12_noise_data.txt', delimiter='\\t')\n",
    "data_3 = np.loadtxt('3N_forces_data.txt', delimiter='\\t')\n",
    "data_4 = np.loadtxt('3N_forces_noise_data.txt', delimiter='\\t')\n",
    "\n",
    "dbscan = DBCSAN()\n",
    "\n",
    "def silhouette_score(estimator, X):\n",
    "    clusters = estimator.fit_predict(X)\n",
    "    score = metrics.calinski_harabasz_score(X, clusters)\n",
    "    return score\n",
    "\n",
    "# Przestrzeń hiperparametrów do przeszukania\n",
    "param_grid1 = {\n",
    "    'max_eps': list(range(1, 30, 1)),\n",
    "    'min_samples': list(range(200, 701, 5)),\n",
    "    'metric': ['l1', 'hamming', 'dice', 'jaccard', 'canberra', 'l2', 'cosine', \n",
    "               'cityblock', 'euclidean', 'manhattan', 'nan_euclidean', 'braycurtis', \n",
    "               'minkowski', 'sokalsneath', 'russellrao', 'seuclidean', 'rogerstanimoto',\n",
    "               'precomputed', 'yule', 'sokalmichener', 'haversine', 'chebyshev', \n",
    "               'correlation', 'sqeuclidean', 'mahalanobis', 'wminkowski', 'matching'],\n",
    "    'leaf_size': list(range(10, 40, 5)),\n",
    "}\n",
    "\n",
    "param_grid2 = {\n",
    "    'max_eps': list(range(1, 30, 1)),\n",
    "    'min_samples': list(range(20, 300, 5)),\n",
    "    'metric': ['l1', 'hamming', 'dice', 'jaccard', 'canberra', 'l2', 'cosine', \n",
    "               'cityblock', 'euclidean', 'manhattan', 'nan_euclidean', 'braycurtis', \n",
    "               'minkowski', 'sokalsneath', 'russellrao', 'seuclidean', 'rogerstanimoto',\n",
    "               'precomputed', 'yule', 'sokalmichener', 'haversine', 'chebyshev', \n",
    "               'correlation', 'sqeuclidean', 'mahalanobis', 'wminkowski', 'matching'],\n",
    "    'leaf_size': list(range(10, 40, 5)),\n",
    "}\n",
    "\n",
    "# Inicjalizacja obiektu HalvingGridSearchCV\n",
    "grid_search1 = HalvingGridSearchCV(dbscan, \n",
    "                                  param_grid1,\n",
    "                                  scoring=silhouette_score,  \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "grid_search2 = HalvingGridSearchCV(dbscan, \n",
    "                                  param_grid1,\n",
    "                                  scoring=silhouette_score,  \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "grid_search3 = HalvingGridSearchCV(dbscan, \n",
    "                                  param_grid2,\n",
    "                                  scoring=silhouette_score,  \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "grid_search4 = HalvingGridSearchCV(dbscan, \n",
    "                                  param_grid2,\n",
    "                                  scoring=silhouette_score,  \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Dopasowanie modelu do danych\n",
    "grid_search1.fit(data_1)\n",
    "grid_search2.fit(data_2)\n",
    "grid_search3.fit(data_3)\n",
    "grid_search4.fit(data_4)\n",
    "\n",
    "# Wydrukowanie najlepszych parametrów\n",
    "print(\"Najlepsze parametry:\", grid_search1.best_params_)\n",
    "print(\"Najlepsze parametry:\", grid_search2.best_params_)\n",
    "print(\"Najlepsze parametry:\", grid_search3.best_params_)\n",
    "print(\"Najlepsze parametry:\", grid_search4.best_params_)\n",
    "# Wydrukowanie najlepszego wyniku\n",
    "#print(\"Najlepszy wynik:\", grid_search1.best_score_)\n",
    "#print(\"Najlepszy wynik:\", grid_search2.best_score_)\n",
    "\n",
    "\n",
    "with open(\"Results_Halving_18.12.txt\", \"w\") as plik:\n",
    "    plik.write(str(grid_search1.best_params_))\n",
    "    plik.write(str(grid_search2.best_params_))\n",
    "    plik.write(str(grid_search3.best_params_))\n",
    "    plik.write(str(grid_search4.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
