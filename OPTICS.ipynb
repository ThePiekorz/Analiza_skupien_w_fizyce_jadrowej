{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbdfd91-2c0b-4650-a7f8-55dd52e4a90f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f282e4-722b-43ae-a06d-79344c887dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm, matplotlib.colors\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import datasets, manifold\n",
    "\n",
    "from time import time\n",
    "import time\n",
    "import warnings\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "\n",
    "from sklearn.cluster import BisectingKMeans, KMeans\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data_1 = np.loadtxt('c12_data.txt', delimiter='\\t')\n",
    "data_2 = np.loadtxt('c12_noise_data.txt', delimiter='\\t')\n",
    "data_3 = np.loadtxt('3N_forces_data.txt', delimiter='\\t')\n",
    "data_4 = np.loadtxt('3N_forces_noise_data.txt', delimiter='\\t')\n",
    "\n",
    "def plot_clusters(data, db_data, labels, n_clusters, noise='k'):\n",
    "    \n",
    "    '''\n",
    "    Parametry:\n",
    "    - data (numpy.ndarray): Dwuwymiarowa tablica zawierająca dane, gdzie każdy wiersz reprezentuje jedną próbkę, a każda kolumna to cecha.\n",
    "    - db_data: Wytrenowany model\n",
    "    - labels (numpy.ndarray): Jednowymiarowa tablica zawierająca przypisane etykiety dla każdej próbki w danych.\n",
    "    - n_clusters (int): Szacowana liczba klastrów w danych.\n",
    "    - noise: Domyślnie 'k', opcjonalnie do wyboru kolor 'none'\n",
    "\n",
    "    '''\n",
    "    unique_labels = set(labels)\n",
    "    core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "    core_samples_mask[db_data.core_sample_indices_] = True\n",
    "\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "            pass\n",
    "\n",
    "        class_member_mask = labels == k\n",
    "        xy = data[class_member_mask & core_samples_mask]\n",
    "        plt.plot(\n",
    "            xy[:, 0],\n",
    "            xy[:, 1],\n",
    "            \"o\",\n",
    "            markerfacecolor=tuple(col),\n",
    "            markeredgecolor=col,\n",
    "            markersize=10,\n",
    "        )\n",
    "\n",
    "        xy = data[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(\n",
    "            xy[:, 0],\n",
    "            xy[:, 1],\n",
    "            \"o\",\n",
    "            markerfacecolor=tuple(col),\n",
    "            markeredgecolor=noise, #or none\n",
    "            markersize=0.5,\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Estimated number of clusters: {n_clusters}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b6c10-92b8-4a7c-8d51-4104ce41eaee",
   "metadata": {},
   "source": [
    "# Coding\n",
    "\n",
    "Najlepsze parametry dla data_1: {'max_eps': 16, 'min_samples': 35}\n",
    "Najlepszy wynik: 447.7126524194085 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57996302-08cd-4e70-ae43-251a32fc507e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyProcess' object has no attribute 'terminate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:215\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repopulate_pool()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:306\u001b[0m, in \u001b[0;36mPool._repopulate_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repopulate_pool_static(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mProcess,\n\u001b[0;32m    307\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes,\n\u001b[0;32m    308\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inqueue,\n\u001b[0;32m    309\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outqueue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializer,\n\u001b[0;32m    310\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs,\n\u001b[0;32m    311\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maxtasksperchild,\n\u001b[0;32m    312\u001b[0m                                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:329\u001b[0m, in \u001b[0;36mPool._repopulate_pool_static\u001b[1;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[0;32m    328\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    330\u001b[0m pool\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\dummy\\__init__.py:51\u001b[0m, in \u001b[0;36mDummyProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39m_children[\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m threading\u001b[38;5;241m.\u001b[39mThread\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:957\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 957\u001b[0m     _start_new_thread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bootstrap, ())\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: can't start new thread",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m optics \u001b[38;5;241m=\u001b[39m OPTICS(max_eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, \n\u001b[0;32m      3\u001b[0m                 min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m, \n\u001b[0;32m      4\u001b[0m                 metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                 n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m                )\u001b[38;5;241m.\u001b[39mfit(data_1)\n\u001b[0;32m      8\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      9\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:345\u001b[0m, in \u001b[0;36mOPTICS.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    337\u001b[0m         X\u001b[38;5;241m.\u001b[39msetdiag(X\u001b[38;5;241m.\u001b[39mdiagonal())\n\u001b[0;32m    338\u001b[0m memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n\u001b[0;32m    340\u001b[0m (\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordering_,\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_distances_,\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreachability_,\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredecessor_,\n\u001b[1;32m--> 345\u001b[0m ) \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(compute_optics_graph)(\n\u001b[0;32m    346\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    347\u001b[0m     min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples,\n\u001b[0;32m    348\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm,\n\u001b[0;32m    349\u001b[0m     leaf_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaf_size,\n\u001b[0;32m    350\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    351\u001b[0m     metric_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params,\n\u001b[0;32m    352\u001b[0m     p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp,\n\u001b[0;32m    353\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    354\u001b[0m     max_eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_eps,\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Extract clusters from the calculated orders and reachability\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:614\u001b[0m, in \u001b[0;36mcompute_optics_graph\u001b[1;34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001b[0m\n\u001b[0;32m    612\u001b[0m     ordering[ordering_idx] \u001b[38;5;241m=\u001b[39m point\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m core_distances_[point] \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39minf:\n\u001b[1;32m--> 614\u001b[0m         _set_reach_dist(\n\u001b[0;32m    615\u001b[0m             core_distances_\u001b[38;5;241m=\u001b[39mcore_distances_,\n\u001b[0;32m    616\u001b[0m             reachability_\u001b[38;5;241m=\u001b[39mreachability_,\n\u001b[0;32m    617\u001b[0m             predecessor_\u001b[38;5;241m=\u001b[39mpredecessor_,\n\u001b[0;32m    618\u001b[0m             point_index\u001b[38;5;241m=\u001b[39mpoint,\n\u001b[0;32m    619\u001b[0m             processed\u001b[38;5;241m=\u001b[39mprocessed,\n\u001b[0;32m    620\u001b[0m             X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    621\u001b[0m             nbrs\u001b[38;5;241m=\u001b[39mnbrs,\n\u001b[0;32m    622\u001b[0m             metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m    623\u001b[0m             metric_params\u001b[38;5;241m=\u001b[39mmetric_params,\n\u001b[0;32m    624\u001b[0m             p\u001b[38;5;241m=\u001b[39mp,\n\u001b[0;32m    625\u001b[0m             max_eps\u001b[38;5;241m=\u001b[39mmax_eps,\n\u001b[0;32m    626\u001b[0m         )\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misinf(reachability_)):\n\u001b[0;32m    628\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    629\u001b[0m         (\n\u001b[0;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll reachability values are inf. Set a larger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    634\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:655\u001b[0m, in \u001b[0;36m_set_reach_dist\u001b[1;34m(core_distances_, reachability_, predecessor_, point_index, processed, X, nbrs, metric, metric_params, p, max_eps)\u001b[0m\n\u001b[0;32m    651\u001b[0m P \u001b[38;5;241m=\u001b[39m X[point_index : point_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    652\u001b[0m \u001b[38;5;66;03m# Assume that radius_neighbors is faster without distances\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;66;03m# and we don't need all distances, nevertheless, this means\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;66;03m# we may be doing some work twice.\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m indices \u001b[38;5;241m=\u001b[39m nbrs\u001b[38;5;241m.\u001b[39mradius_neighbors(P, radius\u001b[38;5;241m=\u001b[39mmax_eps, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    657\u001b[0m \u001b[38;5;66;03m# Getting indices of neighbors that have not been processed\u001b[39;00m\n\u001b[0;32m    658\u001b[0m unproc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcompress(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39mtake(processed, indices), indices)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:1235\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1233\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1234\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(_tree_query_radius_parallel_helper)\n\u001b[1;32m-> 1235\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[0;32m   1236\u001b[0m     delayed_query(\n\u001b[0;32m   1237\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree, X[s], radius, return_distance, sort_results\u001b[38;5;241m=\u001b[39msort_results\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_jobs)\n\u001b[0;32m   1240\u001b[0m )\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[0;32m   1242\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:252\u001b[0m, in \u001b[0;36mPoolManagerMixin.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pool()\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[0;32m    253\u001b[0m         SafeFunction(func), callback\u001b[38;5;241m=\u001b[39mcallback)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:407\u001b[0m, in \u001b[0;36mThreadingBackend._get_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lazily initialize the thread pool\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03mThe actual pool of worker threads is only initialized at the first\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03mcall to apply_async.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m ThreadPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:930\u001b[0m, in \u001b[0;36mThreadPool.__init__\u001b[1;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initargs\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m--> 930\u001b[0m     Pool\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes, initializer, initargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:219\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 219\u001b[0m         p\u001b[38;5;241m.\u001b[39mterminate()\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[0;32m    221\u001b[0m     p\u001b[38;5;241m.\u001b[39mjoin()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DummyProcess' object has no attribute 'terminate'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "optics = OPTICS(max_eps=16, \n",
    "                min_samples=35, \n",
    "                metric='minkowski',\n",
    "                n_jobs=4,\n",
    "               ).fit(data_1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "labels = optics.labels_\n",
    "\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "print(f\"Czas wykonania algorytmu: {execution_time} sekund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0efefa2-1940-4c26-97c8-d51dcd67b584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == -1:\n",
    "        color = 'none'  #  'k' Czarny kolor dla punktów odstających\n",
    "        \n",
    "    class_member_mask = (labels == label)\n",
    "    xy = data_1[class_member_mask]\n",
    "    plt.scatter(xy[:, 0], xy[:, 1], c=[color], label='Cluster %d' % label)\n",
    "\n",
    "plt.title('Optics')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9362ff5c-756c-46b9-8562-7f9e10b293d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1560 fits failed out of a total of 2360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 110\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 115\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 120\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 125\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 130\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 135\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 140\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 145\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 150\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 155\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 160\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 165\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 170\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 175\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 180\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 185\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 190\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 195\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 200\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 205\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 210\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 215\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 220\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 225\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 230\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 235\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 240\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 245\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 250\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 255\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 260\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 265\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 270\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 275\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 280\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 285\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 295\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 730, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 345, in fit\n",
      "    ) = memory.cache(compute_optics_graph)(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 564, in compute_optics_graph\n",
      "    _validate_size(min_samples, n_samples, \"min_samples\")\n",
      "  File \"C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py\", line 393, in _validate_size\n",
      "    raise ValueError(\n",
      "ValueError: min_samples must be no greater than the number of samples (105). Got 300\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " 51.00022707         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan 51.11520791\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  3.51328006         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan  4.0233014          nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan  4.91397588  3.71790169  6.76138023         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  5.10278277  3.69930151  7.21057698 14.39375242         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan  5.04485047\n",
      "  5.94095058  8.76529792 15.24479104 15.90085727         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " 51.00022707         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan 51.11520791\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  8.0716696          nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  8.17397479         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan 29.03008687 29.9570415 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  3.51328006         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan  4.0233014          nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan  4.91397588  3.71790169  6.76138023         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  5.10278277  3.69930151  7.21057698 14.39375242         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan  5.04485047\n",
      "  5.94095058  8.76529792 15.24479104 15.90085727         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " 12.5062539          nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " 20.48489846 24.79953313         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  5.18216791         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan 14.28222101         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan  2.86187615         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan 23.32168071 23.40913993]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  51.00022707\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  51.11520791          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   8.0716696           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   8.17397479          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  29.03008687  29.9570415\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan 123.68018733 121.77353689  47.85382954          nan\n",
      "          nan          nan          nan  76.18044161          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 103.04540528\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan 104.0043281           nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  15.46617284\n",
      "  34.42599815  78.43785421  78.43785421]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   3.51328006          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan   4.0233014           nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   4.91397588   3.71790169   6.76138023          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan   5.10278277\n",
      "   3.69930151   7.21057698  14.39375242          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan   5.04485047   5.94095058\n",
      "   8.76529792  15.24479104  15.90085727          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "  12.5062539           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  20.48489846\n",
      "  24.79953313          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   5.18216791          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan  14.28222101          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   2.86187615          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  23.32168071  23.40913993\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan  46.14266992  16.70818312  48.70231626          nan\n",
      "          nan          nan          nan 172.49042224          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 139.11316593\n",
      " 165.25790128          nan          nan          nan          nan\n",
      "          nan  81.23826774  91.42877913 170.73115857 106.2173147\n",
      " 119.29798407 127.08103946 135.4717699  141.27980971 145.40776992\n",
      " 155.9600442  158.36180775 112.30681774          nan  41.67631895\n",
      "  56.42441405  65.09361051  65.94859813]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  51.00022707\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  51.11520791          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   8.0716696           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   8.17397479          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  29.03008687  29.9570415\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan 123.68018733 121.77353689  47.85382954          nan\n",
      "          nan          nan          nan  76.18044161          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 103.04540528\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan 104.0043281           nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  15.46617284\n",
      "  34.42599815  78.43785421  78.43785421          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan  23.34715712  39.58232486 230.38237801 459.4276283\n",
      "  39.82466634  37.94838819 354.95992796 436.40490964 422.67863188\n",
      " 419.49028829]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   3.51328006          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan   4.0233014           nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   4.91397588   3.71790169   6.76138023          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan   5.10278277\n",
      "   3.69930151   7.21057698  14.39375242          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan   5.04485047   5.94095058\n",
      "   8.76529792  15.24479104  15.90085727          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "  12.5062539           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  20.48489846\n",
      "  24.79953313          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   5.18216791          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan  14.28222101          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   2.86187615          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  23.32168071  23.40913993\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan  46.14266992  16.70818312  48.70231626          nan\n",
      "          nan          nan          nan 172.49042224          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 139.11316593\n",
      " 165.25790128          nan          nan          nan          nan\n",
      "          nan  81.23826774  91.42877913 170.73115857 106.2173147\n",
      " 119.29798407 127.08103946 135.4717699  141.27980971 145.40776992\n",
      " 155.9600442  158.36180775 112.30681774          nan  41.67631895\n",
      "  56.42441405  65.09361051  65.94859813 292.01864659 297.3162285\n",
      " 302.40669223 307.26176232 314.76996229 320.50847316 341.05034935\n",
      " 324.90392197  39.32240391  41.57199908  93.57874346 473.47090322\n",
      "  43.81992015  43.86681441 422.33196909 452.66000395 223.11671192\n",
      " 482.91339572]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  51.00022707\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  51.11520791          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   8.0716696           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   8.17397479          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  29.03008687  29.9570415\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan 123.68018733 121.77353689  47.85382954          nan\n",
      "          nan          nan          nan  76.18044161          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 103.04540528\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan 104.0043281           nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  15.46617284\n",
      "  34.42599815  78.43785421  78.43785421          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan  23.34715712  39.58232486 230.38237801 459.4276283\n",
      "  39.82466634  37.94838819 354.95992796 436.40490964 422.67863188\n",
      " 419.49028829  64.17795252 377.44094829 131.73697705 173.95324444\n",
      " 170.99734892 447.71265242]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   3.51328006          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan   4.0233014           nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   4.91397588   3.71790169   6.76138023          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan   5.10278277\n",
      "   3.69930151   7.21057698  14.39375242          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan   5.04485047   5.94095058\n",
      "   8.76529792  15.24479104  15.90085727          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "  12.5062539           nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan  20.48489846\n",
      "  24.79953313          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan   5.18216791          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan  14.28222101          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "   2.86187615          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan  23.32168071  23.40913993\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan  46.14266992  16.70818312  48.70231626          nan\n",
      "          nan          nan          nan 172.49042224          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan 139.11316593\n",
      " 165.25790128          nan          nan          nan          nan\n",
      "          nan  81.23826774  91.42877913 170.73115857 106.2173147\n",
      " 119.29798407 127.08103946 135.4717699  141.27980971 145.40776992\n",
      " 155.9600442  158.36180775 112.30681774          nan  41.67631895\n",
      "  56.42441405  65.09361051  65.94859813 292.01864659 297.3162285\n",
      " 302.40669223 307.26176232 314.76996229 320.50847316 341.05034935\n",
      " 324.90392197  39.32240391  41.57199908  93.57874346 473.47090322\n",
      "  43.81992015  43.86681441 422.33196909 452.66000395 223.11671192\n",
      " 482.91339572  92.59412205 452.69372236 159.09015056 114.46688558\n",
      " 416.44417882 237.61625462]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'max_eps': 16, 'min_samples': 35}\n",
      "Najlepszy wynik: 447.7126524194085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamil\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_optics.py:992: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    }
   ],
   "source": [
    "# Definicja modelu DBSCAN\n",
    "dbscan = OPTICS()\n",
    "\n",
    "def silhouette_score(estimator, X):\n",
    "    clusters = estimator.fit_predict(X)\n",
    "    score = metrics.calinski_harabasz_score(X, clusters)\n",
    "    return score\n",
    "\n",
    "# Przestrzeń hiperparametrów do przeszukania\n",
    "param_grid = {\n",
    "    'max_eps': list(range(1, 40, 5)),\n",
    "    'min_samples': list(range(10, 301, 5)),\n",
    "}\n",
    "\n",
    "# Inicjalizacja obiektu HalvingGridSearchCV\n",
    "grid_search = HalvingGridSearchCV(dbscan, \n",
    "                                  param_grid,\n",
    "                                  scoring=silhouette_score,  \n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Dopasowanie modelu do danych\n",
    "grid_search.fit(data_1)\n",
    "\n",
    "# Wydrukowanie najlepszych parametrów\n",
    "print(\"Najlepsze parametry:\", grid_search.best_params_)\n",
    "\n",
    "# Wydrukowanie najlepszego wyniku\n",
    "print(\"Najlepszy wynik:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f0414-e2a7-40d7-a689-b07963e0b523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
